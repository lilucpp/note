# 内存模型


1. 《深入理解C++11：C++11新特性解析与应用》中6.3中有介绍，简单看一下。
2. [memory barriers（内存屏障）](https://www.kernel.org/doc/Documentation/memory-barriers.txt)

   ```txt
   // 无关代码是乱序执行的。
   For example, consider the following sequence of events:
   
   	CPU 1		CPU 2
   	===============	===============
   	{ A == 1; B == 2 }
   	A = 3;		x = B;
   	B = 4;		y = A;
   
   The set of accesses as seen by the memory system in the middle can be arranged
   in 24 different combinations:
   
   	STORE A=3,	STORE B=4,	y=LOAD A->3,	x=LOAD B->4
   	STORE A=3,	STORE B=4,	x=LOAD B->4,	y=LOAD A->3
   	STORE A=3,	y=LOAD A->3,	STORE B=4,	x=LOAD B->4
   	STORE A=3,	y=LOAD A->3,	x=LOAD B->2,	STORE B=4
   	STORE A=3,	x=LOAD B->2,	STORE B=4,	y=LOAD A->3
   	STORE A=3,	x=LOAD B->2,	y=LOAD A->3,	STORE B=4
   	STORE B=4,	STORE A=3,	y=LOAD A->3,	x=LOAD B->4
   	STORE B=4, ...
   	...
   
   and can thus result in four different combinations of values:
   
   	x == 2, y == 1
   	x == 2, y == 3
   	x == 4, y == 1
   	x == 4, y == 3
   
   
   Furthermore, the stores committed by a CPU to the memory system may not be
   perceived by the loads made by another CPU in the same order as the stores were
   committed.
   
   // 依赖是顺序执行的，如cpu2中 Q=P,D=*Q
   As a further example, consider this sequence of events:
   
   	CPU 1		CPU 2
   	===============	===============
   	{ A == 1, B == 2, C == 3, P == &A, Q == &C }
   	B = 4;		Q = P;
   	P = &B;		D = *Q;
   
   There is an obvious data dependency here, as the value loaded into D depends on
   the address retrieved from P by CPU 2.  At the end of the sequence, any of the
   following results are possible:
   
   	(Q == &A) and (D == 1)
   	(Q == &B) and (D == 2)
   	(Q == &B) and (D == 4)
   
   Note that CPU 2 will never try and load C into D because the CPU will load P
   into Q before issuing the load of *Q.
   
   // 保证
   There are some minimal guarantees that may be expected of a CPU:
   
    (*) On any given CPU, dependent memory accesses will be issued in order, with
        respect to itself.  This means that for:
   
   	Q = READ_ONCE(P); D = READ_ONCE(*Q);
   
        the CPU will issue the following memory operations:
   
   	Q = LOAD P, D = LOAD *Q
   
        and always in that order.  However, on DEC Alpha, READ_ONCE() also
        emits a memory-barrier instruction, so that a DEC Alpha CPU will
        instead issue the following memory operations:
   
   	Q = LOAD P, MEMORY_BARRIER, D = LOAD *Q, MEMORY_BARRIER
   
        Whether on DEC Alpha or not, the READ_ONCE() also prevents compiler
        mischief.
   
    (*) Overlapping loads and stores within a particular CPU will appear to be
        ordered within that CPU.  This means that for:
   
   	a = READ_ONCE(*X); WRITE_ONCE(*X, b);
   
        the CPU will only issue the following sequence of memory operations:
   
   	a = LOAD *X, STORE *X = b
   
        And for:
   
   	WRITE_ONCE(*X, c); d = READ_ONCE(*X);
   
        the CPU will only issue:
   
   	STORE *X = c, d = LOAD *X
   
        (Loads and stores overlap if they are targeted at overlapping pieces of
        memory).
   // 内存屏障分类
   Memory barriers come in four basic varieties:
   
    (1) Write (or store) memory barriers.
    (2) Data dependency barriers.
    (3) Read (or load) memory barriers.
    (4) General memory barriers.
    ```
3. [理解 C++ 的 Memory Order](http://senlinzhan.github.io/2017/12/04/cpp-memory-order/)
如果不使用任何同步机制（例如 mutex 或 atomic），在多线程中读写同一个变量，那么，程序的结果是难以预料的。简单来说，编译器以及 CPU 的一些行为，会影响到程序的执行结果：

    - 即使是简单的语句，C++ 也不保证是原子操作。
    - CPU 可能会调整指令的执行顺序。
    - 在 CPU cache 的影响下，一个 CPU 执行了某个指令，不会立即被其它 CPU 看见。

4. 然后看cppreference中得关于[memory_order](https://zh.cppreference.com/w/cpp/atomic/memory_order)的介绍。

   - 其中memory_order_relaxed 宽松操作：没有同步或顺序制约，仅对此操作要求原子性（见下方宽松顺序）。
   
   - memory_order_seq_cst  有此内存顺序的加载操作进行获得操作，存储操作进行释放操作，而读修改写操作进行获得操作和释放操作，再加上存在一个单独全序，其中所有线程以同一顺序观测到所有修改（见下方序列一致顺序）。std::atomiac<T>的默认实现。

   - memory_order_acquire 有此内存顺序的加载操作，在其影响的内存位置进行获得操作：当前线程中读或写不能被重排到此加载前。其他释放同一原子变量的线程的所有写入，能为当前线程所见（见下方释放获得顺序）。

   - memory_order_release 有此内存顺序的存储操作进行释放操作：当前线程中的读或写不能被重排到此存储后。当前线程的所有写入，可见于获得该同一原子变量的其他线程（见下方释放获得顺序），并且对该原子变量的带依赖写入变得对于其他消费同一原子对象的线程可见（见下方释放消费顺序）。

   **几种内存顺序**

   - [宽松顺序](https://zh.cppreference.com/w/cpp/atomic/memory_order#.E5.AE.BD.E6.9D.BE.E9.A1.BA.E5.BA.8F)

     带标签 memory_order_relaxed 的原子操作无同步操作；它们不会在共时的内存访问间强加顺序。它们只保证原子性和修改顺序一致性。

     例如，对于最初为零的 `x` 和 `y` ，

     ```c++
     // 线程 1 ：
     r1 = y.load(std::memory_order_relaxed); // A
     x.store(r1, std::memory_order_relaxed); // B
     // 线程 2 ：
     r2 = x.load(std::memory_order_relaxed); // C 
     y.store(42, std::memory_order_relaxed); // D
     ```

     允许产生结果 `r1 == 42 && r2 == 42` .

     宽松内存顺序的典型使用是计数器自增。

     ```c++
     #include <vector>
     #include <iostream>
     #include <thread>
     #include <atomic>
      
     std::atomic<int> cnt = {0};
      
     void f()
     {
         for (int n = 0; n < 1000; ++n) {
             cnt.fetch_add(1, std::memory_order_relaxed);
         }
     }
      
     int main()
     {
         std::vector<std::thread> v;
         for (int n = 0; n < 10; ++n) {
             v.emplace_back(f);
         }
         for (auto& t : v) {
             t.join();
         }
         std::cout << "Final counter value is " << cnt << '\n';
     }
     ```

     输出：

     ```c++
     Final counter value is 10000
     ```

   -  [释放获得顺序](https://zh.cppreference.com/w/cpp/atomic/memory_order#.E9.87.8A.E6.94.BE.E8.8E.B7.E5.BE.97.E9.A1.BA.E5.BA.8F)

     若线程 A 中的一个原子存储带标签 memory_order_release ，而线程 B 中来自同一变量的原子加载带标签 memory_order_acquire ，则从线程 A 的视角*先发生于*原子存储的所有内存写入（非原子及宽松原子的），在线程 B 中成为*可见副效应*，**即一旦原子加载完成，则保证线程 B 能观察到线程 A 写入内存的所有内容。**
     
     **同步仅建立在*释放*和*获得*同一原子对象的线程之间。其他线程可能看到与被同步线程的一者或两者相异的内存访问顺序。**
     
     在强顺序系统（ x86 、 SPARC TSO 、 IBM 主框架）上，释放获得顺序对于多数操作是自动进行的。无需为此同步模式添加额外的 CPU 指令，只有某些编译器优化受影响（例如，编译器被禁止将非原子存储移到原子存储-释放后，或将非原子加载移到原子加载-获得前）。在弱顺序系统（ ARM 、 Itanium 、 Power PC ）上，必须使用特别的 CPU 加载或内存栅栏指令。
     
     ```c++
     #include <thread>
     #include <atomic>
     #include <cassert>
     #include <string>
      
     std::atomic<std::string*> ptr;
     int data;
      
     void producer()
     {
         std::string* p  = new std::string("Hello");
         data = 42;
         ptr.store(p, std::memory_order_release);
     }
      
     void consumer()
     {
         std::string* p2;
         while (!(p2 = ptr.load(std::memory_order_acquire)))
             ;
         assert(*p2 == "Hello"); // 绝无问题
         assert(data == 42); // 绝无问题
     }
      
     int main()
     {
         std::thread t1(producer);
         std::thread t2(consumer);
         t1.join(); t2.join();
     }
     ```

   - [序列一致顺序](https://zh.cppreference.com/w/cpp/atomic/memory_order#.E5.BA.8F.E5.88.97.E4.B8.80.E8.87.B4.E9.A1.BA.E5.BA.8F)
 
   若在多生产者-多消费者的情形中，且所有消费者都必须以相同顺序观察到所有生产者的动作出现，则可能必须有序列顺序。全序列顺序在所有多核系统上要求完全的内存栅栏 CPU 指令。这可能成为性能瓶颈，因为它强制受影响的内存访问传播到每个核心。此示例演示序列一直顺序为必要的场合。任何其他顺序都可能触发assert，因为可能令线程c和d观测到原子对象x和y以相反顺序更改。
     ```c++
     #include <thread>
     #include <atomic>
     #include <cassert>
      
     std::atomic<bool> x = {false};
     std::atomic<bool> y = {false};
     std::atomic<int> z = {0};
      
     void write_x()
     {
         x.store(true, std::memory_order_seq_cst);
     }
      
     void write_y()
     {
         y.store(true, std::memory_order_seq_cst);
     }
      
     void read_x_then_y()
     {
         while (!x.load(std::memory_order_seq_cst))
             ;
         if (y.load(std::memory_order_seq_cst)) {
             ++z;
         }
     }
      
     void read_y_then_x()
     {
         while (!y.load(std::memory_order_seq_cst))
             ;
         if (x.load(std::memory_order_seq_cst)) {
             ++z;
         }
     }
      
     int main()
     {
         std::thread a(write_x);
         std::thread b(write_y);
         std::thread c(read_x_then_y);
         std::thread d(read_y_then_x);
         a.join(); b.join(); c.join(); d.join();
         assert(z.load() != 0);  // 决不发生
     }
     ```
